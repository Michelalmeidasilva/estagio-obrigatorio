\section{Estudo de Agentes Conversacionais: Fluxos Determinísticos (Período: 01/11 a 15/11)}

\subsection{Contextualização da tarefa}
Esta tarefa teve como objetivo um estudo para compreender os fundamentos de \textit{Conversational Agents}, focando especificamente em fluxos deterministicos. Os estudos envolveu o aprendizado de como estruturar conversas rígidas e controladas usando FSM.

\subsection{Objetivos de Aprendizado} Desenvolver competências em design de fluxos determinísticos (\textit{Flows}) para processos que exigem alta confiabilidade e auditabilidade.

O estudo focou em compreender como garantir que cada etapa de um fluxo conversacional seja validada, especialmente em contextos críticos como agendamento médico, onde não pode haver margem para erro ou ambiguidade.

\subsection{Fundamentação Teórica e Prática}

\subsubsection{Pesquisa sobre FSM}
A primeira etapa do estudo consistiu em pesquisar e compreender o conceito de FSM aplicado a chatbots. Estudei como traduzir processos de negócio em diagramas de estados, identificando:

\begin{itemize}
    \item \textbf{Estados (Pages):} Representam cada etapa do fluxo conversacional (ex: coleta de especialidade, data, horário).
    \item \textbf{Transições (Routes):} Condições que permitem a mudança de um estado para outro.
    \item \textbf{Validações:} Regras que garantem a integridade dos dados coletados antes de prosseguir.
\end{itemize}

\subsubsection{Estudo de NLP}
Aprofundei o conhecimento sobre como sistemas de NLP interpretam linguagem humana através de:

\textbf{Intents (Intenções):} Estudei como treinar o modelo para reconhecer diferentes formas de expressar a mesma intenção. Por exemplo, as frases abaixo representam a mesma intenção de agendamento:

\begin{lstlisting}[language=text, caption={Variações Linguísticas para Treinamento de Intent}]
``Quero marcar um cardiologista''
``Preciso de uma consulta para amanha''
``Tem vaga para doutor Paulo?''
``Gostaria de agendar um horario''
``Quero consulta com dermatologista''
\end{lstlisting}

\textbf{Entidades (Entities):} Compreendi como o sistema extrai informações específicas de frases em linguagem natural. Exemplo de análise:

Entrada do usuário: \textit{``Quero ir na unidade Centro na sexta-feira''}

Extração automática:
\begin{itemize}
    \item \texttt{@unidade}: ``Centro'' (entidade customizada)
    \item \texttt{@sys.date}: ``2024-11-29'' (entidade de sistema que converte expressões temporais)
\end{itemize}

\subsubsection{Aplicação Prática: Modelagem de Fluxo de Agendamento}
Com base nos estudos teóricos, modelei um fluxo conversacional completo aplicando o conceito de Slot Filling (preenchimento obrigatório de campos):

\begin{enumerate}
    \item \textbf{Estado ``Início'':} Captura a especialidade médica desejada.
    \item \textbf{Estado ``Coleta de Unidade'':} Permanece em loop até que o parâmetro \texttt{\$session.params.unidade} seja preenchido.
    \item \textbf{Estado ``Coleta de Data'':} Valida se a data informada é futura e está dentro do período permitido (30 dias).
    \item \textbf{Estado ``Coleta de Horário'':} Apresenta opções de horários disponíveis.
    \item \textbf{Estado ``Confirmação'':} Exibe resumo completo para validação do usuário.
    \item \textbf{Estado ``Finalização'':} Processa o agendamento e gera protocolo.
\end{enumerate}

\subsubsection{Estudo de Lógica Condicional em Fluxos Conversacionais}
Pesquisei como implementar rotas condicionais para controlar transições entre estados:

\begin{lstlisting}[language=text, caption={Exemplo de Lógica Condicional Estudada}]
SE $session.params.confirmacao = ``sim'' ENTAO
    Transitar para Estado ``Finalizacao''

SE $session.params.confirmacao = ``nao'' ENTAO
    Limpar todos os parametros
    Retornar para Estado ``Inicio''
\end{lstlisting}

\subsubsection{Análise de Estratégias de Tratamento de Erros}
Estudei técnicas para tornar sistemas conversacionais mais robustos:

\begin{itemize}
    \item \textbf{Validação Contextual:} Aprendi a implementar validações que consideram o contexto (ex: rejeitar datas passadas com mensagens explicativas).
    \item \textbf{Fallback Progressivo:} Pesquisei estratégias de degradação gradual, onde após múltiplas falhas de compreensão, o sistema oferece alternativas (ex: transferência para atendimento humano).
    \item \textbf{Princípio Fail-Safe:} Estudei a importância de confirmações explícitas em processos críticos, onde o usuário revisa todas as informações antes da execução final.
\end{itemize}

\subsubsection{Metodologia de Validação de Sistemas Conversacionais}
Como parte do estudo, pesquisei metodologias de teste para chatbots, resultando na elaboração de cenários de validação conforme a Tabela \ref{tab:testes_dialogflow}.

\begin{table}[h!]
    \centering
    \caption{Cenários de Teste Estudados para Validação de Chatbots}
    \begin{tabular}{p{0.45\textwidth}|p{0.45\textwidth}}
        \hline
        \textbf{Cenário de Teste} & \textbf{Comportamento Esperado (Aprendizado)} \\ \hline
        Fluxo completo com dados válidos & Compreender o caminho feliz e geração de confirmações. \\ \hline
        Tentativa de entrada inválida (data passada) & Estudar validações contextuais e mensagens de erro amigáveis. \\ \hline
        Usuário fornece informações incompletas & Analisar o comportamento de Slot Filling e persistência de estado. \\ \hline
        Usuário desiste durante o processo & Compreender estratégias de cancelamento e limpeza de sessão. \\ \hline
        Teste de fallback após múltiplas falhas & Estudar degradação gradual e transferência para canal alternativo. \\ \hline
        Integração com sistemas externos & Pesquisar comunicação via webhooks e tratamento de latência. \\ \hline
        Confirmação antes da ação crítica & Analisar padrões de UX para operações irreversíveis. \\ \hline
    \end{tabular}
    \label{tab:testes_dialogflow}
    \vspace{0.3em}
    \noindent{\small Fonte: Do próprio autor}
\end{table}

\subsubsection{Competências Desenvolvidas}
Ao final deste estudo, foram desenvolvidas as seguintes competências:
\begin{itemize}
    \item Modelagem de fluxos conversacionais usando FSM
    \item Compreensão de conceitos de NLP (intents, entities, context)
    \item Design de experiências conversacionais para processos críticos
    \item Estratégias de validação e tratamento de erros em chatbots
    \item Metodologias de teste para sistemas conversacionais
\end{itemize}

\section{Estudo de Arquiteturas Híbridas: Fluxos Parcialmente Generativos (Período: 10/11 a 20/11)}

\subsection{Contextualização da tarefa}
Esta tarefa focou em estudar a categoria de \textit{Partly Generative Flows}, que combina a segurança dos fluxos determinísticos com a flexibilidade da IA Generativa. A pesquisa focou no uso de \textit{Generators} para enriquecer interações sem perder o controle do fluxo principal.

\subsection{Objetivos de Aprendizado}
Desenvolver competências em design de arquiteturas híbridas que utilizam \textit{Generators} e \textit{Generative Fallback} estrategicamente.

O estudo explorou como tomar decisões arquiteturais baseadas em análise de risco: operações financeiras exigem fluxos rígidos e auditáveis, enquanto consultas informativas podem aproveitar a flexibilidade da IA generativa.

\subsection{Fundamentação Teórica e Prática}

\subsubsection{Pesquisa sobre Paradigmas}
Estudei metodologias para classificar funcionalidades por nível de risco e determinar qual paradigma aplicar em cada caso:

\begin{itemize}
    \item \textbf{Paradigma Determinístico:} Aplicado tanto em operações de alto risco (PIX e Boletos, via \textit{Flows}) quanto em consultas de saldo de médio risco (via \textit{API} Direta).
    \item \textbf{Paradigma Híbrido:} Utilizado para funcionalidades consultivas de médio risco, como sugestões de investimento.
    \item \textbf{Paradigma Generativo:} Destinado a interações educacionais de baixo risco, como a explicação de termos financeiros.
\end{itemize}


\subsubsection{Competências Desenvolvidas}
Ao final deste estudo, foram desenvolvidas as seguintes competências:
\begin{itemize}
    \item Análise de risco aplicada a decisões arquiteturais
    \item Design de sistemas híbridos com segregação de responsabilidades
    \item Compreensão de fluxos determinísticos para operações críticas
    \item Aplicação de IA generativa em contextos de baixo risco
    \item Técnicas de prompt engineering para modelos de linguagem
    \item Estratégias de hand-off entre paradigmas distintos
\end{itemize}

\section{Estudo de Arquitetura Serverless com Google Cloud Platform (GCP) Cloud Functions (Período: 15/11 a 24/11)}

\subsection{Contextualização da Tarefa}
Esta tarefa focou em compreender o paradigma de computação serverless e sua aplicação em integrações de sistemas. A pesquisa envolveu o aprendizado de webhooks, Cloud Functions e padrões de integração entre sistemas conversacionais e APIs legadas.

\subsection{Objetivos de Aprendizado}
\textbf{Objetivo Principal:} Desenvolver competências em design e implementação de backends serverless para integração de sistemas heterogêneos.

O estudo explorou como webhooks atuam como ponte entre camadas conversacionais (Dialogflow) e APIs internas, executando lógica de negócio e consultas a bancos de dados.

\subsection{Fundamentação Teórica e Prática}

\subsubsection{Pesquisa sobre Padrão API Gateway}
Estudei o padrão arquitetural API Gateway e como Cloud Functions podem atuar como orquestradores:

\begin{itemize}
    \item \textbf{Entrada:} Requisição HTTP POST do Agente contendo os parâmetros da sessão.
    \item \textbf{Processamento:} Lógica de negócio e chamadas a APIs internas (REST).
    \item \textbf{Saída:} Resposta formatada no protocolo do Agente (JSON estruturado).
\end{itemize}

\subsubsection{Implementação do Webhook de Rastreamento}
Para o caso de uso de rastreamento de encomendas em um sistema de logística, implementei a Cloud Function conforme detalhado na Listagem \ref{lst:webhook} do Apêndice \ref{apendice:api}.


\subsubsection{Boas Práticas Implementadas}

\begin{itemize}
    \item \textbf{Validação de Entrada:} Todos os parâmetros recebidos do Dialogflow são validados antes do processamento.
    \item \textbf{Timeout e Retry:} Implementei timeout de 5 segundos nas chamadas HTTP para evitar que o usuário fique esperando indefinidamente.
    \item \textbf{Tratamento de Erros:} Erros são logados (para debugging) e mensagens amigáveis são retornadas ao usuário.
    \item \textbf{Segurança:} Credenciais de API são armazenadas como variáveis de ambiente (Secret Manager do GCP), nunca no código.
    \item \textbf{Logging:} Utilizei o Cloud Logging para rastreabilidade e debugging em produção.
\end{itemize}

\subsubsection{Deploy e Configuração no GCP}
O processo de deploy seguiu as melhores práticas de CI/CD:

\begin{enumerate}
    \item \textbf{Desenvolvimento Local:} Testes locais usando o Functions Framework.
    \item \textbf{Versionamento:} Código versionado no Git com tags semânticas.
    \item \textbf{Deploy:} Utilizei o comando \texttt{gcloud functions deploy} com configuração de memória (256MB) e timeout (60s).
    \item \textbf{Configuração de Trigger:} A função foi configurada para aceitar requisições HTTP autenticadas.
    \item \textbf{Integração com o Agente:} A URL da Cloud Function foi configurada no webhook do Conversational Agent.
\end{enumerate}

\subsubsection{Testes e Validação}
A validação foi realizada em múltiplas camadas, conforme evidenciado na Tabela \ref{tab:testes_webhook}.

\begin{table}[h!]
    \centering
    \caption{Testes de Validação do Webhook de Rastreamento}
    \begin{tabular}{p{0.45\textwidth}|p{0.45\textwidth}}
        \hline
        \textbf{Cenário de Teste} & \textbf{Verificação (Assert)} \\ \hline
        Código de rastreamento válido & A função deve retornar o status correto da API da transportadora. \\ \hline
        Código de rastreamento inválido & A função deve retornar mensagem de erro amigável sem falhar. \\ \hline
        API da transportadora indisponível & A função deve retornar mensagem de erro após timeout e logar o erro. \\ \hline
        Teste de carga (100 req/s) & A Cloud Function deve escalar automaticamente sem degradação de performance. \\ \hline
        Validação de segurança & Requisições sem token de autenticação devem ser rejeitadas (HTTP 401). \\ \hline
        Teste de latência & O tempo de resposta total (Dialogflow + Webhook + API) deve ser inferior a 3 segundos. \\ \hline
    \end{tabular}
    \label{tab:testes_webhook}
    \vspace{0.3em}
    \noindent{\small Fonte: Do próprio autor}
\end{table}

\subsubsection{Competências Desenvolvidas}
Ao final deste estudo, foram desenvolvidas as seguintes competências:
\begin{itemize}
    \item Compreensão do paradigma de computação serverless
    \item Design e implementação de webhooks para integração de sistemas
    \item Aplicação do padrão API Gateway em arquiteturas distribuídas
    \item Tratamento de erros e validação de entrada em APIs
    \item Configuração e deploy de Cloud Functions no GCP
    \item Boas práticas de segurança (Secret Manager, autenticação)
    \item Metodologias de teste para integrações assíncronas
\end{itemize}

\section{Estudo de RAG com Data Stores e Vertex AI (Período: 20/11 a 24/11)}

\subsection{Contextualização da tarefa}
Esta tarefa teve como o foco estudar sobre a implementação de Retrieval-Augmented Generation (RAG) utilizando a abstração de \textit{Data Stores} do ecossistema Conversational Agents. A pesquisa focou em como conectar agentes a fontes de dados não estruturadas (PDFs, sites) de forma nativa.

\subsection{Objetivos de Aprendizado}
\textbf{Objetivo Principal:} Desenvolver competências em configuração de \textit{Data Stores}, ingestão de documentos e integração com modelos generativos para respostas fundamentadas.

O estudo explorou o desafio de criar assistentes capazes de responder perguntas sobre documentos extensos (ex: manual de 50 páginas) de forma precisa e contextualizada, mantendo citações às fontes originais.

\subsection{Fundamentação Teórica e Prática}

\subsubsection{Pesquisa sobre Arquitetura RAG}
Estudei o padrão arquitetural RAG e suas etapas fundamentais:

\begin{enumerate}
    \item \textbf{Ingestão de Documentos:} Upload do PDF ``Normas da Empresa 2024'' para o Vertex AI Search.
    \item \textbf{Chunking e Indexação:} O documento é dividido em chunks semânticos e indexado com embeddings vetoriais.
    \item \textbf{Retrieval (Busca):} Quando o usuário faz uma pergunta, o sistema busca os chunks mais relevantes usando similaridade vetorial.
    \item \textbf{Augmentation (Aumento):} Os chunks recuperados são injetados no contexto do prompt do modelo generativo.
    \item \textbf{Generation (Geração):} O modelo (Gemini Pro) gera a resposta baseada no contexto recuperado.
\end{enumerate}


\section{Estudo de Protocolos e Kits de Desenvolvimento para Agentes: ADK e MCP (Período: 10/11 a 20/11)}

\subsection{Contextualização da Tarefa}
Esta tarefa focou em estudar duas tecnologias emergentes: o \textit{Agent Development Kit} (ADK) para construção de agentes complexos e o \textit{Model Context Protocol} (MCP) para padronização da conexão entre modelos de IA e fontes de dados externas.

\subsection{Objetivos de Aprendizado}
\textbf{Objetivo Principal:} Compreender e implementar padrões modernos de arquitetura de agentes, focando na interoperabilidade e na capacidade de uso de ferramentas (tool use).

O estudo buscou superar as limitações de integrações ad-hoc (como webhooks rígidos) explorando o protocolo MCP, que permite que assistentes de IA descubram e utilizem recursos de forma dinâmica e padronizada.

\subsection{Fundamentação Teórica e Prática}

\subsubsection{Pesquisa sobre Model Context Protocol (MCP)}
Estudei a especificação do protocolo MCP, que define uma arquitetura cliente-servidor para conectar IAs a sistemas:

\begin{itemize}
    \item \textbf{MCP Hosts:} Aplicações que ``consomem'' o contexto (ex: IDEs, Chatbots).
    \item \textbf{MCP Servers:} Serviços que expõem recursos, prompts e ferramentas.
    \item \textbf{MCP Clients:} O conector que mantém a sessão entre Host e Server.
\end{itemize}

A principal vantagem identificada foi a dissociação: um único servidor MCP (ex: ``Conector Google Drive'') pode ser reutilizado por múltiplos agentes sem reescrita de código.

Para fixar o aprendizado, desenvolvi um servidor MCP em TypeScript que expõe uma base de dados local de produtos para um agente (ver Listagem \ref{lst:mcp-server} no Apêndice \ref{apendice:api}).


\subsubsection{Estudo de Agent Development Kit (ADK)}
Explorei frameworks e kits de desenvolvimento (ADK) que facilitam a orquestração de agentes. O foco foi entender como esses kits abstraem a complexidade de:

\begin{itemize}
    \item \textbf{Gerenciamento de Memória:} Como o agente ``lembra'' de interações passadas.
    \item \textbf{Planejamento (Planning):} Capacidade do agente de quebrar uma tarefa complexa (``Planejar viagem'') em sub-tarefas (``Ver voos'', ``Reservar hotel'').
    \item \textbf{Execução de Ferramentas:} O uso autônomo de ferramentas expostas via MCP ou APIs.
\end{itemize}

\subsubsection{Competências Desenvolvidas}
Ao final desta tarefa, foram desenvolvidas as seguintes competências:
\begin{itemize}
    \item Compreensão da arquitetura de Agentes Autônomos
    \item Implementação de servidores compatíveis com o padrão MCP
    \item Desenvolvimento de ferramentas (Tools) para consumo por LLMs
    \item Análise de trade-offs entre integrações estáticas e dinâmicas
    \item Uso de SDKs para orquestração de agentes (ADK)
    \item Debugging de comunicação via transporte stdio/SSE
\end{itemize}
